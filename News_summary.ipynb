{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Importing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-12T07:18:10.331606Z",
     "iopub.status.busy": "2025-04-12T07:18:10.331293Z",
     "iopub.status.idle": "2025-04-12T07:18:55.291635Z",
     "shell.execute_reply": "2025-04-12T07:18:55.290895Z",
     "shell.execute_reply.started": "2025-04-12T07:18:10.331577Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets evaluate rouge_score -q\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOADING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:18:55.293006Z",
     "iopub.status.busy": "2025-04-12T07:18:55.292538Z",
     "iopub.status.idle": "2025-04-12T07:18:58.340151Z",
     "shell.execute_reply": "2025-04-12T07:18:58.339358Z",
     "shell.execute_reply.started": "2025-04-12T07:18:55.292984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64722bfe0b02473f88acdfa9c3d73214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b309a65f12004fe99152e52d5b61ede6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train.csv:   0%|          | 0.00/46.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c870f30e5e47e2840bcc6782786252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test.csv:   0%|          | 0.00/16.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9825574faa5d4673ad9213f094036a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "val.csv:   0%|          | 0.00/3.37M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52ae61d475d4297964935ac588ceff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/12565 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3f4f1a96ca4d7ea8899f5f5fe9962a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71aeb233ca814b719d2f79ff09dfa378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/898 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'Article', 'Heading', 'Summary'],\n",
       "        num_rows: 12565\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'Article', 'Heading', 'Summary'],\n",
       "        num_rows: 4487\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'Article', 'Heading', 'Summary'],\n",
       "        num_rows: 898\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"ILSUM/ILSUM-1.0\", \"English\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPLITTING INTO TRAIN, VALIDATION AND TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:18:58.342119Z",
     "iopub.status.busy": "2025-04-12T07:18:58.341889Z",
     "iopub.status.idle": "2025-04-12T07:18:59.171503Z",
     "shell.execute_reply": "2025-04-12T07:18:59.170518Z",
     "shell.execute_reply.started": "2025-04-12T07:18:58.342097Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4fd04cf7dd34882a1fc63f13bf6f4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/12565 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64561f04ddcd42d6b07db44d2297d079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/4487 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bfbb1e22c6449982e552383aaebb14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/898 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_INPUT_LENGTH = 512\n",
    "MAX_TARGET_LENGTH = 128\n",
    "\n",
    "def filter_long_examples(example):\n",
    "    return len(example[\"Article\"].split()) < 500 and len(example[\"Summary\"].split()) < 100\n",
    "\n",
    "# IMPORTANT: use dataset[\"train\"], dataset[\"test\"], dataset[\"validation\"]\n",
    "filtered_train = dataset[\"train\"].filter(filter_long_examples)\n",
    "filtered_test = dataset[\"test\"].filter(filter_long_examples)\n",
    "filtered_validation = dataset[\"validation\"].filter(filter_long_examples)\n",
    "\n",
    "dataset_final = {\n",
    "    \"train\": filtered_train,\n",
    "    \"validation\": filtered_validation,\n",
    "    \"test\": filtered_test\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTING BART MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:18:59.173150Z",
     "iopub.status.busy": "2025-04-12T07:18:59.172866Z",
     "iopub.status.idle": "2025-04-12T07:19:00.942009Z",
     "shell.execute_reply": "2025-04-12T07:19:00.941344Z",
     "shell.execute_reply.started": "2025-04-12T07:18:59.173104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2660647341b412091510a07ff972d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c44942b2d20d404196fffbea6ee04675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e6905fa0faa449db55e709209157e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e0982e02a14449b47278d74ed8fa24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_checkpoint = \"facebook/bart-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:19:00.943080Z",
     "iopub.status.busy": "2025-04-12T07:19:00.942772Z",
     "iopub.status.idle": "2025-04-12T07:19:09.457549Z",
     "shell.execute_reply": "2025-04-12T07:19:09.456715Z",
     "shell.execute_reply.started": "2025-04-12T07:19:00.943050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cdd21e8e6f40a89dd3bd06f2764f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7710 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6ce197ff8e46dd8341006853f2b631",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7970eb4df54600863520aaeba43f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2707 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = examples[\"Article\"]\n",
    "    targets = examples[\"Summary\"]\n",
    "    model_inputs = tokenizer(inputs, max_length=MAX_INPUT_LENGTH, truncation=True)\n",
    "    labels = tokenizer(targets, max_length=MAX_TARGET_LENGTH, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = {k: v.map(preprocess_function, batched=True) for k, v in dataset_final.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOADING PRE-TRAINED WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:19:09.458688Z",
     "iopub.status.busy": "2025-04-12T07:19:09.458376Z",
     "iopub.status.idle": "2025-04-12T07:19:12.899955Z",
     "shell.execute_reply": "2025-04-12T07:19:12.899038Z",
     "shell.execute_reply.started": "2025-04-12T07:19:09.458664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07d1b5e96f7a463b9a47d136bbc5e974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETTING EVALUATION METRICS AND DEFINING BATCHSIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:19:12.901338Z",
     "iopub.status.busy": "2025-04-12T07:19:12.901020Z",
     "iopub.status.idle": "2025-04-12T07:19:14.323452Z",
     "shell.execute_reply": "2025-04-12T07:19:14.322753Z",
     "shell.execute_reply.started": "2025-04-12T07:19:12.901313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab792f61aedc4cb4a324d1e33ac58417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    return {k: round(v * 100, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:19:14.325654Z",
     "iopub.status.busy": "2025-04-12T07:19:14.325411Z",
     "iopub.status.idle": "2025-04-12T07:19:14.329003Z",
     "shell.execute_reply": "2025-04-12T07:19:14.328387Z",
     "shell.execute_reply.started": "2025-04-12T07:19:14.325632Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETTING TRAINING ARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:19:14.330229Z",
     "iopub.status.busy": "2025-04-12T07:19:14.329938Z",
     "iopub.status.idle": "2025-04-12T07:19:14.513078Z",
     "shell.execute_reply": "2025-04-12T07:19:14.512413Z",
     "shell.execute_reply.started": "2025-04-12T07:19:14.330193Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./bart-news-summarizer\",\n",
    "    run_name=\"bart-news-summarization-run\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True,\n",
    "    report_to=None,\n",
    "    fp16=torch.cuda.is_available()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:19:14.514330Z",
     "iopub.status.busy": "2025-04-12T07:19:14.514009Z",
     "iopub.status.idle": "2025-04-12T07:19:14.518096Z",
     "shell.execute_reply": "2025-04-12T07:19:14.517233Z",
     "shell.execute_reply.started": "2025-04-12T07:19:14.514303Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE TRAINER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:19:14.519058Z",
     "iopub.status.busy": "2025-04-12T07:19:14.518833Z",
     "iopub.status.idle": "2025-04-12T07:19:15.243228Z",
     "shell.execute_reply": "2025-04-12T07:19:15.242293Z",
     "shell.execute_reply.started": "2025-04-12T07:19:14.519040Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-5b960f886c01>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:19:15.244419Z",
     "iopub.status.busy": "2025-04-12T07:19:15.244119Z",
     "iopub.status.idle": "2025-04-12T07:19:15.248264Z",
     "shell.execute_reply": "2025-04-12T07:19:15.247329Z",
     "shell.execute_reply.started": "2025-04-12T07:19:15.244396Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['WANDB_DISABLED'] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:19:15.249536Z",
     "iopub.status.busy": "2025-04-12T07:19:15.249198Z",
     "iopub.status.idle": "2025-04-12T07:51:53.405277Z",
     "shell.execute_reply": "2025-04-12T07:51:53.404386Z",
     "shell.execute_reply.started": "2025-04-12T07:19:15.249513Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5784' max='5784' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5784/5784 32:34, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.378300</td>\n",
       "      <td>0.316255</td>\n",
       "      <td>36.330900</td>\n",
       "      <td>26.558300</td>\n",
       "      <td>33.813900</td>\n",
       "      <td>33.780900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.297300</td>\n",
       "      <td>0.305778</td>\n",
       "      <td>36.742100</td>\n",
       "      <td>27.049500</td>\n",
       "      <td>34.151200</td>\n",
       "      <td>34.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.257200</td>\n",
       "      <td>0.307433</td>\n",
       "      <td>37.093700</td>\n",
       "      <td>27.807800</td>\n",
       "      <td>34.650900</td>\n",
       "      <td>34.641600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5784, training_loss=0.3341655243152075, metrics={'train_runtime': 1957.7872, 'train_samples_per_second': 11.814, 'train_steps_per_second': 2.954, 'total_flos': 6678980519178240.0, 'train_loss': 0.3341655243152075, 'epoch': 3.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVALUATING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:51:53.406769Z",
     "iopub.status.busy": "2025-04-12T07:51:53.406403Z",
     "iopub.status.idle": "2025-04-12T07:56:59.676032Z",
     "shell.execute_reply": "2025-04-12T07:56:59.675213Z",
     "shell.execute_reply.started": "2025-04-12T07:51:53.406732Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='677' max='677' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [677/677 05:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.29115334153175354,\n",
       " 'eval_rouge1': 37.2619,\n",
       " 'eval_rouge2': 27.5054,\n",
       " 'eval_rougeL': 34.4019,\n",
       " 'eval_rougeLsum': 34.3945,\n",
       " 'eval_runtime': 306.2583,\n",
       " 'eval_samples_per_second': 8.839,\n",
       " 'eval_steps_per_second': 2.211,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING ON RANDOM SAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-12T07:57:40.595727Z",
     "iopub.status.busy": "2025-04-12T07:57:40.595331Z",
     "iopub.status.idle": "2025-04-12T07:57:41.103524Z",
     "shell.execute_reply": "2025-04-12T07:57:41.102619Z",
     "shell.execute_reply.started": "2025-04-12T07:57:40.595696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Article: Indian-origin boy finds millions of years old fossil in UK gardenA six-year-old Indian-origin boy says he is “really excited” after he found a fossil from millions of years ago while digging in his garden in the West Midlands region of England. Siddak Singh Jhamat, known as Sid, was using a fossil-hunting set he received as a Christmas present when he came across a rock that looked like a horn.\"I was just digging for worms and things like pottery and bricks and I just came across this rock which looked a bit like a horn, and thought it could be a tooth or a claw or a horn, but it was actually a piece of coral which is called horn coral,\" the schoolboy said.\"I was really excited about what it really was,\" he said.According to a BBC report, his father Vish Singh was able to identify the horn coral through a fossil group he is a member of on Facebook and estimates the fossil is between 251 to 488 million years old.\"We were surprised he found something so odd-shaped in the soil... he found a horn coral, and some smaller pieces next to it, then the next day he went digging again and found a congealed block of sand,” said Vish Singh.“In that there were loads of little molluscs and sea shells, and something called a crinoid, which is like a tentacle of a squid, so it's quite a prehistoric thing,\" he said.Singh believes the fossil's markings mean it is most likely a Rugosa coral and that the period that they existed from was between 500 and 251 million years ago, the Paleozoic Era.\"England at the time was part of Pangea, a landmass of continents. England was all underwater as well... that's quite a significant expanse of time,\" said Vish Singh.The family, from Walsall, said they do not live in an area known for its fossils, like the Jurassic Coast in the south of England, but that they do have a lot of natural clay in the garden where the fossils were found.Singh added: \"Lots and lots of people have commented on how amazing it is to find something in the back garden.\"They say you can find fossils anywhere if you look carefully enough, but to find a significantly large piece like that is quite unique.\"They now hope to tell Birmingham University's Museum of Geology about their discovery.\n",
      "\n",
      "Reference Summary: Siddak Singh Jhamat, known as Sid, was using a fossil-hunting set he received as a Christmas present when he came across a rock that looked like a horn.\n",
      "\n",
      "Generated Summary: A six-year-old Indian-origin boy says he is “really excited” after he found a fossil from millions of years ago while digging in his garden in the West Midlands region of England.\n"
     ]
    }
   ],
   "source": [
    "sample = dataset_final[\"test\"][0]\n",
    "inputs = tokenizer(sample[\"Article\"], return_tensors=\"pt\", max_length=MAX_INPUT_LENGTH, truncation=True).to(model.device)\n",
    "\n",
    "summary_ids = model.generate(**inputs, max_length=MAX_TARGET_LENGTH)\n",
    "print(\"Original Article:\", sample[\"Article\"])\n",
    "print(\"\\nReference Summary:\", sample[\"Summary\"])\n",
    "print(\"\\nGenerated Summary:\", tokenizer.decode(summary_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
